%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional\else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
\fi\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}

\usepackage{geometry}
\usepackage{multirow}
\usepackage{eqparbox}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{2}



\title{Disvoice Documentation}
\date{Mar 04, 2021}
\release{0.1.1}
\author{Camilo Vasquez}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}


\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{disvoice_logo}.png}

DisVoice is a python framework designed to compute features from speech files. Disvoice computes glottal, phonation, articulation, prosody, phonological, and features representation learnig strategies using autoencders. The features can be computed both from sustained vowels and continuous speech utterances with the aim to recognize praliguistic aspects from speech.

The features can be used in classifiers to recognize emotions, or communication capabilities of patients with different speech disorders including diseases with functional origin such as larinx cancer or nodules; craneo-facial based disorders such as hipernasality developed by cleft-lip and palate; or neurodegenerative disorders such as Parkinson's or Hungtinton's diseases.

The features are also suitable to evaluate mood problems like depression based on speech patterns.

For additional details about each feature type, and how to use DisVoice, please check


\chapter{Glottal features}
\label{\detokenize{Glottal::doc}}\label{\detokenize{Glottal:glottal-features}}\label{\detokenize{Glottal:welcome-to-disvoice-s-documentation}}
\noindent\sphinxincludegraphics[width=800\sphinxpxdimen]{{glottal_vowel}.png}
\phantomsection\label{\detokenize{Glottal:module-glottal}}\index{glottal (module)}\index{Glottal (class in glottal)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.Glottal}}\pysigline{\sphinxstrong{class }\sphinxcode{glottal.}\sphinxbfcode{Glottal}}
Compute features based on the glottal source reconstruction from sustained vowels and continuous speech.

For continuous speech, the features are computed over voiced segments

Nine descriptors are computed:
\begin{enumerate}
\item {} 
Variability of time between consecutive glottal closure instants (GCI)

\item {} 
Average opening quotient (OQ) for consecutive glottal cycles-\textgreater{} rate of opening phase duration / duration of glottal cycle

\item {} 
Variability of opening quotient (OQ) for consecutive glottal cycles-\textgreater{} rate of opening phase duration /duration of glottal cycle

\item {} 
Average normalized amplitude quotient (NAQ) for consecutive glottal cycles-\textgreater{} ratio of the amplitude quotient and the duration of the glottal cycle

\item {} 
Variability of normalized amplitude quotient (NAQ) for consecutive glottal cycles-\textgreater{} ratio of the amplitude quotient and the duration of the glottal cycle

\item {} 
Average H1H2: Difference between the first two harmonics of the glottal flow signal

\item {} 
Variability H1H2: Difference between the first two harmonics of the glottal flow signal

\item {} 
Average of Harmonic richness factor (HRF): ratio of the sum of the harmonics amplitude and the amplitude of the fundamental frequency

\item {} 
Variability of HRF

\end{enumerate}

Static or dynamic matrices can be computed:

Static matrix is formed with 36 features formed with (9 descriptors) x (4 functionals: mean, std, skewness, kurtosis)

Dynamic matrix is formed with the 9 descriptors computed for frames of 200 ms length with a time-shift of 50 ms.

Notes:
\begin{enumerate}
\item {} 
The fundamental frequency is computed using the RAPT algorithm.

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{glottal}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}or\PYGZus{}folder\PYGZus{}audio}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}features}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{dynamic\PYGZus{}or\PYGZus{}static}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{plots} \PYG{p}{(}\PYG{n}{true}\PYG{p}{,}  \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n+nb}{format} \PYG{p}{(}\PYG{n}{csv}\PYG{p}{,} \PYG{n}{txt}\PYG{p}{,} \PYG{n}{npy}\PYG{p}{,} \PYG{n}{kaldi}\PYG{p}{,} \PYG{n}{torch}\PYG{p}{)}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Examples command line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{glottal}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{glottalfeaturesAst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{static}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{glottal}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/098\PYGZus{}u1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{glottalfeaturesUst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{static}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{glottal}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/098\PYGZus{}u1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{glottalfeaturesUst.ark}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dynamic}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{glottal}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/098\PYGZus{}u1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{glottalfeaturesUst.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dynamic}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

Examples directly in Python

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{disvoice}\PYG{n+nn}{.}\PYG{n+nn}{glottal} \PYG{k+kn}{import} \PYG{n}{Glottal}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{glottal}\PYG{o}{=}\PYG{n}{Glottal}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{numpy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{dynamic}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audios}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audios}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{numpy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audios}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audios}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\index{extract\_features\_file() (glottal.Glottal method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.Glottal.extract_features_file}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_file}}{\emph{audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the glottal features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldi features, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{glottal}\PYG{o}{=}\PYG{n}{Glottal}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{extract\_features\_path() (glottal.Glottal method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.Glottal.extract_features_path}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_path}}{\emph{path\_audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the glottal features for audios inside a path
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_audio} -- directory with (.wav) audio files inside, sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldifeatures, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{glottal}\PYG{o}{=}\PYG{n}{Glottal}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{extract\_glottal\_signal() (glottal.Glottal method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.Glottal.extract_glottal_signal}}\pysiglinewithargsret{\sphinxbfcode{extract\_glottal\_signal}}{\emph{x}, \emph{fs}}{}
Extract the glottal flow and the glottal flow derivative signals
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{x} -- data from the speech signal.

\item {} 
\sphinxstyleliteralstrong{fs} -- sampling frequency

\end{itemize}

\item[{Returns}] \leavevmode
glottal signal

\item[{Returns}] \leavevmode
derivative  of the glottal signal

\item[{Returns}] \leavevmode
glottal closure instants

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{io}\PYG{n+nn}{.}\PYG{n+nn}{wavfile} \PYG{k+kn}{import} \PYG{n}{read}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{glottal}\PYG{o}{=}\PYG{n}{Glottal}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fs}\PYG{p}{,} \PYG{n}{data\PYGZus{}audio}\PYG{o}{=}\PYG{n}{read}\PYG{p}{(}\PYG{n}{audio}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{glottal}\PYG{p}{,} \PYG{n}{g\PYGZus{}iaif}\PYG{p}{,} \PYG{n}{GCIs}\PYG{o}{=}\PYG{n}{glottal}\PYG{o}{.}\PYG{n}{extract\PYGZus{}glottal\PYGZus{}signal}\PYG{p}{(}\PYG{n}{data\PYGZus{}audio}\PYG{p}{,} \PYG{n}{fs}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{plot\_glottal() (glottal.Glottal method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.Glottal.plot_glottal}}\pysiglinewithargsret{\sphinxbfcode{plot\_glottal}}{\emph{data\_audio}, \emph{fs}, \emph{GCI}, \emph{glottal\_flow}, \emph{glottal\_sig}}{}
Plots of the glottal features
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{data\_audio} -- speech signal.

\item {} 
\sphinxstyleliteralstrong{fs} -- sampling frequency

\item {} 
\sphinxstyleliteralstrong{GCI} -- glottal closure instants

\item {} 
\sphinxstyleliteralstrong{glottal\_flow} -- glottal flow

\item {} 
\sphinxstyleliteralstrong{glottal\_sig} -- reconstructed glottal signal

\end{itemize}

\item[{Returns}] \leavevmode
plots of the glottal features.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{SE\_VQ\_varF0() (in module glottal)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.SE_VQ_varF0}}\pysiglinewithargsret{\sphinxcode{glottal.}\sphinxbfcode{SE\_VQ\_varF0}}{\emph{x}, \emph{fs}, \emph{f0=None}}{}
Function to extract GCIs using an adapted version of the SEDREAMS 
algorithm which is optimised for non-modal voice qualities (SE-VQ). Ncand maximum
peaks are selected from the LP-residual signal in the interval defined by
the mean-based signal.

A dynamic programming algorithm is then used to select the optimal path of GCI locations. 
Then a post-processing method, using the output of a resonator applied to the residual signal, is
carried out to remove false positives occurring in creaky speech regions.

Note that this method is slightly different from the standard SE-VQ
algorithm as the mean based signal is calculated using a variable window
length.

This is set using an f0 contour interpolated over unvoiced
regions and heavily smoothed. This is particularly useful for speech
involving large f0 excursions (i.e. very expressive speech).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{x} -- speech signal (in samples)

\item {} 
\sphinxstyleliteralstrong{fs} -- sampling frequency (Hz)

\item {} 
\sphinxstyleliteralstrong{f0} -- f0 contour (optional), otherwise its computed  using the RAPT algorithm

\end{itemize}

\item[{Returns}] \leavevmode
GCI Glottal closure instants (in samples)

\end{description}\end{quote}
\begin{description}
\item[{References:}] \leavevmode
Kane, J., Gobl, C., (2013) {\color{red}\bfseries{}{}`}Evaluation of glottal closure instant 
detection in a range of voice qualities', Speech Communication
55(2), pp. 295-314.

\end{description}

ORIGINAL FUNCTION WAS CODED BY JOHN KANE AT THE PHONETICS AND SPEECH LAB IN 
TRINITY COLLEGE DUBLIN ON 2013.

THE SEDREAMS FUNCTION WAS CODED BY THOMAS DRUGMAN OF THE UNIVERSITY OF MONS

THE CODE WAS TRANSLATED TO PYTHON AND ADAPTED BY J. C. Vasquez-Correa
AT PATTERN RECOGNITION LAB UNIVERSITY OF ERLANGEN NUREMBER- GERMANY
AND UNIVERSTY OF ANTIOQUIA, COLOMBIA
\sphinxhref{mailto:JCAMILO.VASQUEZ@UDEA.EDU.CO}{JCAMILO.VASQUEZ@UDEA.EDU.CO}
https//jcvasquezc.github.io

\end{fulllineitems}

\index{IAIF() (in module glottal)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.IAIF}}\pysiglinewithargsret{\sphinxcode{glottal.}\sphinxbfcode{IAIF}}{\emph{x}, \emph{fs}, \emph{GCI}}{}
Function to carry out iterative and adaptive inverse filtering (Alku et al 1992).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{x} -- speech signal (in samples)

\item {} 
\sphinxstyleliteralstrong{fs} -- sampling frequency (in Hz)

\item {} 
\sphinxstyleliteralstrong{GCI} -- Glottal closure instants (in samples)

\end{itemize}

\item[{Returns}] \leavevmode
glottal flow derivative estimate

\end{description}\end{quote}

Function Coded by John Kane @ The Phonetics and Speech Lab
Trinity College Dublin, August 2012

THE CODE WAS TRANSLATED TO PYTHON AND ADAPTED BY J. C. Vasquez-Correa
AT PATTERN RECOGNITION LAB UNIVERSITY OF ERLANGEN NUREMBER- GERMANY
AND UNIVERSTY OF ANTIOQUIA, COLOMBIA
\sphinxhref{mailto:JCAMILO.VASQUEZ@UDEA.EDU.CO}{JCAMILO.VASQUEZ@UDEA.EDU.CO}
https//jcvasquezc.github.io

\end{fulllineitems}

\index{get\_vq\_params() (in module glottal)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Glottal:glottal.get_vq_params}}\pysiglinewithargsret{\sphinxcode{glottal.}\sphinxbfcode{get\_vq\_params}}{\emph{gf}, \emph{gfd}, \emph{fs}, \emph{GCI}}{}
Function to estimate the glottal parameters: NAQ, QOQ, H1-H2, and HRF

This function can be used to estimate a range of conventional glottal
source parameters often used in the literature. This includes: the
normalized amplitude quotient (NAQ), the quasi-open quotient (QOQ), the
difference in amplitude of the first two harmonics of the differentiated
glottal source spectrum (H1-H2), and the harmonic richness factor (HRF)
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{gf} -- {[}samples{]} {[}N{]} Glottal flow estimation

\item {} 
\sphinxstyleliteralstrong{gfd} -- {[}samples{]} {[}N{]} Glottal flow derivative estimation

\item {} 
\sphinxstyleliteralstrong{fs} -- {[}Hz{]} {[}1{]} sampling frequency

\item {} 
\sphinxstyleliteralstrong{GCI} -- {[}samples{]} {[}M{]} Glottal closure instants

\end{itemize}

\item[{Returns}] \leavevmode
NAQ {[}s,samples{]} {[}Mx2{]} Normalised amplitude quotient

\item[{Returns}] \leavevmode
QOQ{[}s,samples{]} {[}Mx2{]} Quasi-open quotient

\item[{Returns}] \leavevmode
H1H2{[}s,dB{]} {[}Mx2{]} Difference in glottal harmonic amplitude

\item[{Returns}] \leavevmode
HRF{[}s,samples{]} {[}Mx2{]} Harmonic richness factor

\end{description}\end{quote}
\begin{description}
\item[{References:}] \leavevmode
{[}1{]} Alku, P., B ackstrom, T., and Vilkman, E. Normalized amplitude quotient for parameterization of the glottal flow. Journal of the Acoustical Society of America, 112(2):701-710, 2002.

{[}2{]} Hacki, T. Klassifizierung von glottisdysfunktionen mit hilfe der elektroglottographie. Folia Phoniatrica, pages 43-48, 1989.

{[}3{]} Alku, P., Strik, H., and Vilkman, E. Parabolic spectral parameter - A new method for quantification of the glottal flow. Speech Communication, 22(1):67-79, 1997.

{[}4{]} Hanson, H. M. Glottal characteristics of female speakers: Acoustic correlates. Journal of the Acoustical Society of America, 10(1):466-481, 1997.

{[}5{]} Childers, D. G. and Lee, C. K. Voice quality factors: Analysis, synthesis and perception. Journal of the Acoustical Society of  America, 90(5):2394-2410, 1991.

\end{description}

Function Coded by John Kane @ The Phonetics and Speech Lab
Trinity College Dublin, August 2012

THE CODE WAS TRANSLATED TO PYTHON AND ADAPTED BY J. C. Vasquez-Correa
AT PATTERN RECOGNITION LAB UNIVERSITY OF ERLANGEN NUREMBERGER- GERMANY
AND UNIVERSTY OF ANTIOQUIA, COLOMBIA
\sphinxhref{mailto:JCAMILO.VASQUEZ@UDEA.EDU.CO}{JCAMILO.VASQUEZ@UDEA.EDU.CO}
https//jcvasquezc.github.io

\end{fulllineitems}



\chapter{Phonation features}
\label{\detokenize{Phonation:phonation-features}}\label{\detokenize{Phonation::doc}}
\noindent\sphinxincludegraphics[width=800\sphinxpxdimen]{{phonation_vowel}.png}
\phantomsection\label{\detokenize{Phonation:module-phonation}}\index{phonation (module)}
Created on Jul 21 2017

@author: J. C. Vasquez-Correa
\index{Phonation (class in phonation)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Phonation:phonation.Phonation}}\pysigline{\sphinxstrong{class }\sphinxcode{phonation.}\sphinxbfcode{Phonation}}
Compute phonation features from sustained vowels and continuous speech.

For continuous speech, the features are computed over voiced segments

Seven descriptors are computed:
\begin{enumerate}
\item {} 
First derivative of the fundamental Frequency

\item {} 
Second derivative of the fundamental Frequency

\item {} 
Jitter

\item {} 
Shimmer

\item {} 
Amplitude perturbation quotient

\item {} 
Pitch perturbation quotient

\item {} 
Logaritmic Energy

\end{enumerate}

Static or dynamic matrices can be computed:

Static matrix is formed with 29 features formed with (seven descriptors) x (4 functionals: mean, std, skewness, kurtosis) + degree of Unvoiced

Dynamic matrix is formed with the seven descriptors computed for frames of 40 ms.

Notes:
\begin{enumerate}
\item {} 
In dynamic features the first 11 frames of each recording are not considered to be able to stack the APQ and PPQ descriptors with the remaining ones.

\item {} 
The fundamental frequency is computed the RAPT algorithm. To use the PRAAT method,  change the \sphinxquotedblleft{}self.pitch method\sphinxquotedblright{} variable in the class constructor.

\end{enumerate}

Script is called as follows

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonation}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}or\PYGZus{}folder\PYGZus{}audio}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}features}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{static} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{plots} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n+nb}{format} \PYG{p}{(}\PYG{n}{csv}\PYG{p}{,} \PYG{n}{txt}\PYG{p}{,} \PYG{n}{npy}\PYG{p}{,} \PYG{n}{kaldi}\PYG{p}{,} \PYG{n}{torch}\PYG{p}{)}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Examples command line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonationfeaturesAst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/098\PYGZus{}u1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonationfeaturesUst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/098\PYGZus{}u1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonationfeaturesUdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonationfeaturesst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonationfeaturesst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonationfeaturesdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

Examples directly in Python

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{disvoice}\PYG{n+nn}{.}\PYG{n+nn}{phonation} \PYG{k+kn}{import} \PYG{n}{Phonation}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonation}\PYG{o}{=}\PYG{n}{Phonation}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{numpy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{dynamic}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audios}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audios}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{numpy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audios}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audios}\PYG{p}{,} \PYG{n}{static}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\index{extract\_features\_file() (phonation.Phonation method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Phonation:phonation.Phonation.extract_features_file}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_file}}{\emph{audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the phonation features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldi features, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonation}\PYG{o}{=}\PYG{n}{Phonation}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{extract\_features\_path() (phonation.Phonation method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Phonation:phonation.Phonation.extract_features_path}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_path}}{\emph{path\_audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the phonation features for audios inside a path
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_audio} -- directory with (.wav) audio files inside, sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldifeatures, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonation}\PYG{o}{=}\PYG{n}{Phonation}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{plot\_phon() (phonation.Phonation method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Phonation:phonation.Phonation.plot_phon}}\pysiglinewithargsret{\sphinxbfcode{plot\_phon}}{\emph{data\_audio}, \emph{fs}, \emph{F0}, \emph{logE}}{}
Plots of the phonation features
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{data\_audio} -- speech signal.

\item {} 
\sphinxstyleliteralstrong{fs} -- sampling frequency

\item {} 
\sphinxstyleliteralstrong{F0} -- contour of the fundamental frequency

\item {} 
\sphinxstyleliteralstrong{logE} -- contour of the log-energy

\end{itemize}

\item[{Returns}] \leavevmode
plots of the phonation features.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Articulation features}
\label{\detokenize{Articulation::doc}}\label{\detokenize{Articulation:articulation-features}}
\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{articulation_transition}.png}
\phantomsection\label{\detokenize{Articulation:module-articulation}}\index{articulation (module)}
Created on Jul 21 2017

@author: J. C. Vasquez-Correa
\index{Articulation (class in articulation)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Articulation:articulation.Articulation}}\pysigline{\sphinxstrong{class }\sphinxcode{articulation.}\sphinxbfcode{Articulation}}
Compute articulation features from continuous speech.

122 descriptors are computed:

1-22. Bark band energies in onset transitions (22 BBE).

23-34. Mel frequency cepstral coefficients in onset transitions (12 MFCC onset)

35-46. First derivative of the MFCCs in onset transitions (12 DMFCC onset)

47-58. Second derivative of the MFCCs in onset transitions (12 DDMFCC onset)

59-80. Bark band energies in offset transitions (22 BBE).

81-92. MFCCC in offset transitions (12 MFCC offset)

93-104. First derivative of the MFCCs in offset transitions (12 DMFCC offset)

105-116. Second derivative of the MFCCs in offset transitions (12 DMFCC offset)
\begin{enumerate}
\setcounter{enumi}{116}
\item {} 
First formant Frequency

\item {} 
First Derivative of the first formant frequency

\item {} 
Second Derivative of the first formant frequency

\item {} 
Second formant Frequency

\item {} 
First derivative of the Second formant Frequency

\item {} 
Second derivative of the Second formant Frequency

\end{enumerate}

Static or dynamic matrices can be computed:

Static matrix is formed with 488 features formed with (122 descriptors) x (4 functionals: mean, std, skewness, kurtosis)

Dynamic matrix are formed with the 58 descriptors (22 BBEs, 12 MFCC, 12DMFCC, 12 DDMFCC ) computed for frames of 40 ms with a time-shift of 20 ms in onset transitions.

The first two frames of each recording are not considered for dynamic analysis to be able to stack the derivatives of MFCCs

Notes:
1. The first two frames of each recording are not considered for dynamic analysis to be able to stack the derivatives of MFCCs
2. The fundamental frequency is computed the PRAAT algorithm. To use the RAPT method,  change the \sphinxquotedblleft{}self.pitch method\sphinxquotedblright{} variable in the class constructor.

Script is called as follows

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{articulation}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}or\PYGZus{}folder\PYGZus{}audio}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}features}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{static} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{plots} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n+nb}{format} \PYG{p}{(}\PYG{n}{csv}\PYG{p}{,} \PYG{n}{txt}\PYG{p}{,} \PYG{n}{npy}\PYG{p}{,} \PYG{n}{kaldi}\PYG{p}{,} \PYG{n}{torch}\PYG{p}{)}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Examples command line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{articulation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{articulation\PYGZus{}featuresDDKst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{txt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{articulation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{articulation\PYGZus{}featuresDDKst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{csv}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{articulation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{articulation\PYGZus{}featuresDDKst.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{torch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{articulation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{articulation\PYGZus{}featuresDDKdyn.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{txt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{articulation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{articulation\PYGZus{}featuresDDKdyn.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{csv}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{articulation}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{articulation\PYGZus{}featuresDDKdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{torch}
\end{sphinxVerbatim}

Examples directly in Python

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{articulation}\PYG{o}{=}\PYG{n}{Articulation}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\index{extract\_features\_file() (articulation.Articulation method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Articulation:articulation.Articulation.extract_features_file}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_file}}{\emph{audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the articulation features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldi features, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{articulation}\PYG{o}{=}\PYG{n}{Articulation}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{extract\_features\_path() (articulation.Articulation method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Articulation:articulation.Articulation.extract_features_path}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_path}}{\emph{path\_audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the articulation features for audios inside a path
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_audio} -- directory with (.wav) audio files inside, sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldifeatures, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{articulation}\PYG{o}{=}\PYG{n}{Articulation}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{articulation}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{plot\_art() (articulation.Articulation method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Articulation:articulation.Articulation.plot_art}}\pysiglinewithargsret{\sphinxbfcode{plot\_art}}{\emph{data\_audio}, \emph{fs}, \emph{F0}, \emph{F1}, \emph{F2}, \emph{segmentsOn}, \emph{segmentsOff}}{}
Plots of the articulation features
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{data\_audio} -- speech signal.

\item {} 
\sphinxstyleliteralstrong{fs} -- sampling frequency

\item {} 
\sphinxstyleliteralstrong{F0} -- contour of the fundamental frequency

\item {} 
\sphinxstyleliteralstrong{F1} -- contour of the 1st formant

\item {} 
\sphinxstyleliteralstrong{F2} -- contour of the 2nd formant

\item {} 
\sphinxstyleliteralstrong{segmentsOn} -- list with the onset segments

\item {} 
\sphinxstyleliteralstrong{segmentsOff} -- list with the offset segments

\end{itemize}

\item[{Returns}] \leavevmode
plots of the articulation features.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Prosody features}
\label{\detokenize{Prosody::doc}}\label{\detokenize{Prosody:prosody-features}}
\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{prosody1}.png}
\phantomsection\label{\detokenize{Prosody:module-prosody}}\index{prosody (module)}
Created on Jul 21 2017, Modified Apr 10 2018.

@author: J. C. Vasquez-Correa, T. Arias-Vergara, J. S. Guerrero
\index{Prosody (class in prosody)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Prosody:prosody.Prosody}}\pysigline{\sphinxstrong{class }\sphinxcode{prosody.}\sphinxbfcode{Prosody}}
Compute prosody features from continuous speech based on duration, fundamental frequency and energy.
Static or dynamic matrices can be computed:
Static matrix is formed with 103 features and include

1-6     F0-contour:                                                       Avg., Std., Max., Min., Skewness, Kurtosis

7-12    Tilt of a linear estimation of F0 for each voiced segment:        Avg., Std., Max., Min., Skewness, Kurtosis

13-18   MSE of a linear estimation of F0 for each voiced segment:         Avg., Std., Max., Min., Skewness, Kurtosis

19-24   F0 on the first voiced segment:                                   Avg., Std., Max., Min., Skewness, Kurtosis

25-30   F0 on the last voiced segment:                                    Avg., Std., Max., Min., Skewness, Kurtosis

31-34   energy-contour for voiced segments:                               Avg., Std., Skewness, Kurtosis

35-38   Tilt of a linear estimation of energy contour for V segments:     Avg., Std., Skewness, Kurtosis

39-42   MSE of a linear estimation of energy contour for V segment:       Avg., Std., Skewness, Kurtosis

43-48   energy on the first voiced segment:                               Avg., Std., Max., Min., Skewness, Kurtosis

49-54   energy on the last voiced segment:                                Avg., Std., Max., Min., Skewness, Kurtosis

55-58   energy-contour for unvoiced segments:                             Avg., Std., Skewness, Kurtosis

59-62   Tilt of a linear estimation of energy contour for U segments:     Avg., Std., Skewness, Kurtosis

63-66   MSE of a linear estimation of energy contour for U segments:      Avg., Std., Skewness, Kurtosis

67-72   energy on the first unvoiced segment:                             Avg., Std., Max., Min., Skewness, Kurtosis

73-78   energy on the last unvoiced segment:                              Avg., Std., Max., Min., Skewness, Kurtosis

79      Voiced rate:                                                      Number of voiced segments per second

80-85   Duration of Voiced:                                               Avg., Std., Max., Min., Skewness, Kurtosis

86-91   Duration of Unvoiced:                                             Avg., Std., Max., Min., Skewness, Kurtosis

92-97   Duration of Pauses:                                               Avg., Std., Max., Min., Skewness, Kurtosis

98-103  Duration ratios:                                                 Pause/(Voiced+Unvoiced), Pause/Unvoiced, Unvoiced/(Voiced+Unvoiced),Voiced/(Voiced+Unvoiced), Voiced/Puase, Unvoiced/Pause

Dynamic matrix is formed with 13 features computed for each voiced segment and contains

1-6. Coefficients of 5-degree Lagrange polynomial to model F0 contour

7-12. Coefficients of 5-degree Lagrange polynomial to model energy contour
\begin{enumerate}
\setcounter{enumi}{12}
\item {} 
Duration of the voiced segment

\end{enumerate}

Dynamic prosody features are based on
Najim Dehak, \sphinxquotedblleft{}Modeling Prosodic Features With Joint Factor Analysis for Speaker Verification\sphinxquotedblright{}, 2007

Script is called as follows

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}or\PYGZus{}folder\PYGZus{}audio}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}features}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{static} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{plots} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n+nb}{format} \PYG{p}{(}\PYG{n}{csv}\PYG{p}{,} \PYG{n}{txt}\PYG{p}{,} \PYG{n}{npy}\PYG{p}{,} \PYG{n}{kaldi}\PYG{p}{,} \PYG{n}{torch}\PYG{p}{)}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Examples command line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{prosodyfeaturesAst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{prosodyfeaturesUst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{prosodyfeaturesUdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{prosodyfeaturesst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{prosodyfeaturesst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{prosodyfeaturesdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{prosody}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{prosodyfeaturesdyn.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

Examples directly in Python

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{=}\PYG{n}{Prosody}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\index{extract\_features\_file() (prosody.Prosody method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Prosody:prosody.Prosody.extract_features_file}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_file}}{\emph{audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the prosody features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldi features, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{=}\PYG{n}{Prosody}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{extract\_features\_path() (prosody.Prosody method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Prosody:prosody.Prosody.extract_features_path}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_path}}{\emph{path\_audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the prosody features for audios inside a path
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_audio} -- directory with (.wav) audio files inside, sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldifeatures, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{=}\PYG{n}{Prosody}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{plot\_pros() (prosody.Prosody method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Prosody:prosody.Prosody.plot_pros}}\pysiglinewithargsret{\sphinxbfcode{plot\_pros}}{\emph{data\_audio}, \emph{fs}, \emph{F0}, \emph{segmentsV}, \emph{segmentsU}, \emph{F0\_features}}{}
Plots of the prosody features
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{data\_audio} -- speech signal.

\item {} 
\sphinxstyleliteralstrong{fs} -- sampling frequency

\item {} 
\sphinxstyleliteralstrong{F0} -- contour of the fundamental frequency

\item {} 
\sphinxstyleliteralstrong{segmentsV} -- list with the voiced segments

\item {} 
\sphinxstyleliteralstrong{segmentsU} -- list with the unvoiced segments

\item {} 
\sphinxstyleliteralstrong{F0\_features} -- vector with f0-based features

\end{itemize}

\item[{Returns}] \leavevmode
plots of the prosody features.

\end{description}\end{quote}

\end{fulllineitems}

\index{prosody\_dynamic() (prosody.Prosody method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Prosody:prosody.Prosody.prosody_dynamic}}\pysiglinewithargsret{\sphinxbfcode{prosody\_dynamic}}{\emph{audio}}{}
Extract the dynamic prosody features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item[{Returns}] \leavevmode
array (N,13) with the prosody features extracted from an audio file.  N= number of voiced segments

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{=}\PYG{n}{Prosody}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{prosody\PYGZus{}dynamic}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{prosody\_static() (prosody.Prosody method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Prosody:prosody.Prosody.prosody_static}}\pysiglinewithargsret{\sphinxbfcode{prosody\_static}}{\emph{audio}, \emph{plots}}{}
Extract the static prosody features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\end{itemize}

\item[{Returns}] \leavevmode
array with the 103 prosody features

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prosody}\PYG{o}{=}\PYG{n}{Prosody}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features}\PYG{o}{=}\PYG{n}{prosody}\PYG{o}{.}\PYG{n}{prosody\PYGZus{}static}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Phonological features}
\label{\detokenize{Phonological::doc}}\label{\detokenize{Phonological:phonological-features}}
\noindent\sphinxincludegraphics[width=800\sphinxpxdimen]{{phonological1}.png}
\phantomsection\label{\detokenize{Phonological:module-phonological}}\index{phonological (module)}
Created on Jun 24 2020

@author: J. C. Vasquez-Correa
\index{Phonological (class in phonological)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Phonological:phonological.Phonological}}\pysigline{\sphinxstrong{class }\sphinxcode{phonological.}\sphinxbfcode{Phonological}}
Compute phonological features from continuous speech files.

18 descriptors are computed, bases on 18 different phonological classes from the phonet toolkit 
\sphinxurl{https://phonet.readthedocs.io/en/latest/?badge=latest}

It computes the phonological log-likelihood ratio features from phonet

Static or dynamic matrices can be computed:

Static matrix is formed with 108 features formed with (18 descriptors) x (6 functionals: mean, std, skewness, kurtosis, max, min)

Dynamic matrix is formed with the 18 descriptors computed for frames of 25 ms with a time-shift of 10 ms.

Script is called as follows

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}or\PYGZus{}folder\PYGZus{}audio}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}features}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{static} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{plots} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n+nb}{format} \PYG{p}{(}\PYG{n}{csv}\PYG{p}{,} \PYG{n}{txt}\PYG{p}{,} \PYG{n}{npy}\PYG{p}{,} \PYG{n}{kaldi}\PYG{p}{,} \PYG{n}{torch}\PYG{p}{)}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Examples command line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonologicalfeaturesAst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonologicalfeaturesUst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonologicalfeaturesUdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonologicalfeaturesst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonologicalfeaturesst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonologicalfeaturesdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{phonological}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{phonologicalfeaturesdyn.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

Examples directly in Python

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{=}\PYG{n}{Phonological}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\index{extract\_features\_file() (phonological.Phonological method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Phonological:phonological.Phonological.extract_features_file}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_file}}{\emph{audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the phonological features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldi features, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{=}\PYG{n}{Phonological}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{=}\PYG{n}{Phonological}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{extract\_features\_path() (phonological.Phonological method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Phonological:phonological.Phonological.extract_features_path}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_path}}{\emph{path\_audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the phonological features for audios inside a path
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_audio} -- directory with (.wav) audio files inside, sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldifeatures, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{=}\PYG{n}{Phonological}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Representation learning features}
\label{\detokenize{RepLearning::doc}}\label{\detokenize{RepLearning:representation-learning-features}}
\noindent\sphinxincludegraphics[width=800\sphinxpxdimen]{{replearning_continuous}.png}

\noindent\sphinxincludegraphics[width=600\sphinxpxdimen]{{replearning_error}.png}
\phantomsection\label{\detokenize{RepLearning:module-replearning}}\index{replearning (module)}\index{RepLearning (class in replearning)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:replearning.RepLearning}}\pysiglinewithargsret{\sphinxstrong{class }\sphinxcode{replearning.}\sphinxbfcode{RepLearning}}{\emph{model}}{}
Feature extraction from speech signals based on representation learning strategies using convolutional and recurrent autoencoders

Two types of features are computed
\begin{enumerate}
\item {} 
256 features extracted from the bottleneck layer of the autoencoders

\item {} 
128 features based on the MSE between the decoded and input spectrograms of the autoencoder in different frequency regions

\end{enumerate}

Additionally, static (for all utterance) or dynamic (for each 500 ms speech segments) features can be computed:
- The static feature vector is formed with 1024 features and contains (384 descriptors) x (4 functionals: mean, std, skewness, kurtosis)
- The dynamic feature matrix is formed with the 384 descriptors computed for speech segments with 500ms length and 250ms time-shift
- You can choose between features computed from a convolutional or recurrent autoencoder

Script is called as follows

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{replearning}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}or\PYGZus{}folder\PYGZus{}audio}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}features}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{static} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{plots} \PYG{p}{(}\PYG{n}{true} \PYG{o+ow}{or} \PYG{n}{false}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n+nb}{format} \PYG{p}{(}\PYG{n}{csv}\PYG{p}{,} \PYG{n}{txt}\PYG{p}{,} \PYG{n}{npy}\PYG{p}{,} \PYG{n}{kaldi}\PYG{p}{,} \PYG{n}{torch}\PYG{p}{)}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{model} \PYG{p}{(}\PYG{n}{CAE}\PYG{p}{,} \PYG{n}{RAE}\PYG{p}{)}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Examples command line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{replearning}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{replearningfeaturesDDKst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CAE}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{replearning}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{replearningfeaturesDDKdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CAE}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{replearning}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{replearningfeaturesst.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CAE}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{replearning}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{replearningfeaturesst.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CAE}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{python} \PYG{n}{replearning}\PYG{o}{.}\PYG{n}{py} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{replearningfeaturesdyn.pt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CAE}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

Examples directly in Python

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{replearning} \PYG{k+kn}{import} \PYG{n}{RepLearning}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{=}\PYG{n}{RepLearning}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CAE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}a1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\index{extract\_features\_file() (replearning.RepLearning method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:replearning.RepLearning.extract_features_file}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_file}}{\emph{audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the representation learning features from an audio file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{audio} -- .wav audio file.

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldi features, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{=}\PYG{n}{RepLearning}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CAE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/001\PYGZus{}ddk1\PYGZus{}PCGITA.wav}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dataframe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}file}\PYG{p}{(}\PYG{n}{file\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{=}\PYG{n}{RepLearning}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CAE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{extract\_features\_path() (replearning.RepLearning method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:replearning.RepLearning.extract_features_path}}\pysiglinewithargsret{\sphinxbfcode{extract\_features\_path}}{\emph{path\_audio}, \emph{static=True}, \emph{plots=False}, \emph{fmt='npy'}, \emph{kaldi\_file='`}}{}
Extract the representation learning features for audios inside a path
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_audio} -- directory with (.wav) audio files inside, sampled at 16 kHz

\item {} 
\sphinxstyleliteralstrong{static} -- whether to compute and return statistic functionals over the feature matrix, or return the feature matrix computed over frames

\item {} 
\sphinxstyleliteralstrong{plots} -- timeshift to extract the features

\item {} 
\sphinxstyleliteralstrong{fmt} -- format to return the features (npy, dataframe, torch, kaldi)

\item {} 
\sphinxstyleliteralstrong{kaldi\_file} -- file to store kaldifeatures, only valid when fmt==\sphinxquotedblright{}kaldi\sphinxquotedblright{}

\end{itemize}

\item[{Returns}] \leavevmode
features computed from the audio file.

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{=}\PYG{n}{RepLearning}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CAE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{path\PYGZus{}audio}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../audios/}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features1}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{replearning}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{npy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features2}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{replearning}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{features3}\PYG{o}{=}\PYG{n}{phonological}\PYG{o}{.}\PYG{n}{replearning}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{replearning}\PYG{o}{.}\PYG{n}{extract\PYGZus{}features\PYGZus{}path}\PYG{p}{(}\PYG{n}{path\PYGZus{}audio}\PYG{p}{,} \PYG{n}{static}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{plots}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{kaldi}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{kaldi\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./test.ark}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{\detokenize{RepLearning:module-AEspeech}}\index{AEspeech (module)}
Feature extraction from speech signals based on representation learning strategies
\index{AEspeech (class in AEspeech)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech}}\pysiglinewithargsret{\sphinxstrong{class }\sphinxcode{AEspeech.}\sphinxbfcode{AEspeech}}{\emph{model}, \emph{units}}{}~\index{compute\_bottleneck\_features() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.compute_bottleneck_features}}\pysiglinewithargsret{\sphinxbfcode{compute\_bottleneck\_features}}{\emph{wav\_file}, \emph{return\_numpy=True}}{}
Compute the the bottleneck features of the autoencoder
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{wav\_file} -- .wav file with a sampling frequency of 16kHz

\item {} 
\sphinxstyleliteralstrong{return\_numpy} -- return the features in a numpy array (True) or a Pytorch tensor (False)

\end{itemize}

\item[{Returns}] \leavevmode
Pytorch tensor (nf, h) or numpy array (nf, h) with the extracted features. nf: number of frames, size of the bottleneck space

\end{description}\end{quote}

\end{fulllineitems}

\index{compute\_dynamic\_features() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.compute_dynamic_features}}\pysiglinewithargsret{\sphinxbfcode{compute\_dynamic\_features}}{\emph{wav\_directory}}{}
Compute both the bottleneck and the reconstruction error features from the autoencoder for wav files inside a directory
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{wav\_directory} -- .wav file with a sampling frequency of 16kHz

\item[{Returns}] \leavevmode
dictionary with the extracted bottleneck and error features, and with information about which frame coresponds to which wav file in the directory.

\end{description}\end{quote}

\end{fulllineitems}

\index{compute\_global\_features() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.compute_global_features}}\pysiglinewithargsret{\sphinxbfcode{compute\_global\_features}}{\emph{wav\_directory}, \emph{stack\_feat=False}}{}
Compute global features (1 vector per utterance) both for the bottleneck and the reconstruction error features from the autoencoder for wav files inside a directory
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{wav\_directory} -- .wav file with a sampling frequency of 16kHz

\item {} 
\sphinxstyleliteralstrong{stack\_feat} -- if True, returns also a feature matrix with the stack of the bottleneck and error features

\end{itemize}

\item[{Returns}] \leavevmode
pandas dataframes with the bottleneck and error features.

\end{description}\end{quote}

\end{fulllineitems}

\index{compute\_rec\_error\_features() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.compute_rec_error_features}}\pysiglinewithargsret{\sphinxbfcode{compute\_rec\_error\_features}}{\emph{wav\_file}, \emph{return\_numpy=True}}{}
Compute the  reconstruction error features from the autoencoder
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{wav\_file} -- .wav file with a sampling frequency of 16kHz

\item {} 
\sphinxstyleliteralstrong{return\_numpy} -- return the features in a numpy array (True) or a Pytorch tensor (False)

\end{itemize}

\item[{Returns}] \leavevmode
Pytorch tensor (nf, 128) or numpy array (nf, 128) with the extracted features. nf: number of frames

\end{description}\end{quote}

\end{fulllineitems}

\index{compute\_rec\_spectrogram() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.compute_rec_spectrogram}}\pysiglinewithargsret{\sphinxbfcode{compute\_rec\_spectrogram}}{\emph{wav\_file}, \emph{return\_numpy=True}}{}
Compute the  reconstructed spectrogram from the autoencoder
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{wav\_file} -- .wav file with a sampling frequency of 16kHz

\item {} 
\sphinxstyleliteralstrong{return\_numpy} -- return the features in a numpy array (True) or a Pytorch tensor (False)

\end{itemize}

\item[{Returns}] \leavevmode
Pytorch tensor (N, C, F, T). N: batch of spectrograms extracted every 500ms, C: number of channels (1),  F: number of Mel frequencies (128), T: time steps (126)

\end{description}\end{quote}

\end{fulllineitems}

\index{compute\_spectrograms() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.compute_spectrograms}}\pysiglinewithargsret{\sphinxbfcode{compute\_spectrograms}}{\emph{wav\_file}}{}
Compute the tensor of Mel-scale spectrograms to be used as input for the autoencoders from a wav file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{wav\_file} -- .wav file with a sampling frequency of 16kHz

\item[{Returns}] \leavevmode
Pytorch tensor (N, C, F, T). N: batch of spectrograms extracted every 500ms, C: number of channels (1),  F: number of Mel frequencies (128), T: time steps (126)

\end{description}\end{quote}

\end{fulllineitems}

\index{destandard() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.destandard}}\pysiglinewithargsret{\sphinxbfcode{destandard}}{\emph{tensor}}{}
destandardize input tensor from the autoencoders
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{tensor} -- standardized input tensor for the AEs (N, 128,126)

\item[{Returns}] \leavevmode
destandardized tensor for the AEs (N, 128,126)

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_spectrograms() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.plot_spectrograms}}\pysiglinewithargsret{\sphinxbfcode{plot\_spectrograms}}{\emph{wav\_file}}{}
Figure of the decoded spectrograms by the AEs
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{wav\_file} -- .wav file with a sampling frequency of 16kHz

\end{description}\end{quote}

\end{fulllineitems}

\index{show\_spectrograms() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.show_spectrograms}}\pysiglinewithargsret{\sphinxbfcode{show\_spectrograms}}{\emph{spectrograms}}{}
Visualization of the computed tensor of Mel-scale spectrograms to be used as input for the autoencoders from a wav file
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{spectrograms} -- tensor of spectrograms obtained from \sphinxcode{compute\_spectrograms(wav-file)}

\end{description}\end{quote}

\end{fulllineitems}

\index{standard() (AEspeech.AEspeech method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{RepLearning:AEspeech.AEspeech.standard}}\pysiglinewithargsret{\sphinxbfcode{standard}}{\emph{tensor}}{}
standardize input tensor for the autoencoders
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{tensor} -- input tensor for the AEs (N, 128,126)

\item[{Returns}] \leavevmode
standardize tensor for the AEs (N, 128,126)

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Need Help?}
\label{\detokenize{help::doc}}\label{\detokenize{help:need-help}}
If you have trouble with Disvoice, please write to Camilo Vasquez at: \sphinxhref{mailto:juan.vasquez@fau.de}{juan.vasquez@fau.de}


\chapter{References}
\label{\detokenize{reference::doc}}\label{\detokenize{reference:references}}
If you use Disvoice for research purposes, please cite the following papers, depending on the features you use:


\section{glottal features}
\label{\detokenize{reference:glottal-features}}
{[}1{]} Belalcázar-Bolaños, E. A., Orozco-Arroyave, J. R., Vargas-Bonilla, J. F., Haderlein, T., \& Nöth, E. (2016, September). Glottal Flow Patterns Analyses for Parkinson’s Disease Detection: Acoustic and Nonlinear Approaches. In International Conference on Text, Speech, and Dialogue (pp. 400-407). Springer.


\section{phonation features}
\label{\detokenize{reference:phonation-features}}
{[}1{]} T. Arias-Vergara, J. C. Vásquez-Correa, J. R. Orozco-Arroyave, Parkinson's Disease and Aging: Analysis of Their Effect in Phonation and Articulation of Speech, Cognitive computation, (2017).

{[}2{]} Vásquez-Correa, J. C., et al. \sphinxquotedblleft{}Towards an automatic evaluation of the dysarthria level of patients with Parkinson's disease.\sphinxquotedblright{} Journal of communication disorders 76 (2018): 21-36.


\section{articulation features}
\label{\detokenize{reference:articulation-features}}
{[}1{]} Vásquez-Correa, J. C., et al. \sphinxquotedblleft{}Towards an automatic evaluation of the dysarthria level of patients with Parkinson's disease.\sphinxquotedblright{} Journal of communication disorders 76 (2018): 21-36.

{[}2{]}. J. R. Orozco-Arroyave, J. C. Vásquez-Correa et al. \sphinxquotedblleft{}NeuroSpeech: An open-source software for Parkinson's speech analysis.\sphinxquotedblright{} Digital Signal Processing (2017).


\section{prosody features}
\label{\detokenize{reference:prosody-features}}
{[}1{]}. N., Dehak, P. Dumouchel, and P. Kenny. \sphinxquotedblleft{}Modeling prosodic features with joint factor analysis for speaker verification.\sphinxquotedblright{} IEEE Transactions on Audio, Speech, and Language Processing 15.7 (2007): 2095-2103.

{[}2{]} Vásquez-Correa, J. C., et al. \sphinxquotedblleft{}Towards an automatic evaluation of the dysarthria level of patients with Parkinson's disease.\sphinxquotedblright{} Journal of communication disorders 76 (2018): 21-36.


\section{phonological features}
\label{\detokenize{reference:phonological-features}}
{[}1{]} Vásquez-Correa, J. C., Klumpp, P., Orozco-Arroyave, J. R., \& Nöth, E. (2019). Phonet: a Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech. Proc. Interspeech 2019, 549-553.


\section{Representation learning features}
\label{\detokenize{reference:representation-learning-features}}
{[}1{]} Vasquez-Correa, J. C., et al. (2020). Parallel Representation Learning for the Classification of Pathological Speech: Studies on Parkinson’s Disease and Cleft Lip and Palate. Speech Communication, 122, 56-67.


\chapter{Installation}
\label{\detokenize{index:installation}}
From the source file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{jcvasquezc}\PYG{o}{/}\PYG{n}{disvoice}
\PYG{n}{cd} \PYG{n}{disvoice}
\PYG{n}{bash} \PYG{n}{install}\PYG{o}{.}\PYG{n}{sh}
\end{sphinxVerbatim}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\chapter{Help}
\label{\detokenize{index:help}}
If you have trouble with Disvoice, please write to Camilo Vasquez at: \sphinxhref{mailto:juan.vasquez@fau.de}{juan.vasquez@fau.de}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{a}
\item {\sphinxstyleindexentry{AEspeech}}\sphinxstyleindexpageref{RepLearning:\detokenize{module-AEspeech}}
\item {\sphinxstyleindexentry{articulation}}\sphinxstyleindexpageref{Articulation:\detokenize{module-articulation}}
\indexspace
\bigletter{g}
\item {\sphinxstyleindexentry{glottal}}\sphinxstyleindexpageref{Glottal:\detokenize{module-glottal}}
\indexspace
\bigletter{p}
\item {\sphinxstyleindexentry{phonation}}\sphinxstyleindexpageref{Phonation:\detokenize{module-phonation}}
\item {\sphinxstyleindexentry{phonological}}\sphinxstyleindexpageref{Phonological:\detokenize{module-phonological}}
\item {\sphinxstyleindexentry{prosody}}\sphinxstyleindexpageref{Prosody:\detokenize{module-prosody}}
\indexspace
\bigletter{r}
\item {\sphinxstyleindexentry{replearning}}\sphinxstyleindexpageref{RepLearning:\detokenize{module-replearning}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}